{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create workspace and experiment instances"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'capstone-spam-classification-experiment'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1664257866236
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Dataset Overview\n",
        "The dataset we are using is a spam classification dataset obtained from kaggle. We are going to perform multi-class text classification. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "try: \n",
        "    training_dataset = Dataset.get_by_name(ws, name='capstone-spam-dataset')\n",
        "\n",
        "except: # data is not found in the workspace\n",
        "    print(\"Data not found in workspace. Please upload and register the data!\")"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1664274686453
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View the dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "     Category                                            Message Column3\n0         ham  Go until jurong point, crazy.. Available only ...    None\n1         ham                      Ok lar... Joking wif u oni...    None\n2        spam  Free entry in 2 a wkly comp to win FA Cup fina...    None\n3         ham  U dun say so early hor... U c already then say...    None\n4         ham  Nah I don't think he goes to usf, he lives aro...    None\n...       ...                                                ...     ...\n5569     spam  This is the 2nd time we have tried 2 contact u...    None\n5570      ham               Will ü b going to esplanade fr home?    None\n5571      ham  Pity, * was in mood for that. So...any other s...    None\n5572      ham  The guy did some bitching but I acted like i'd...    None\n5573      ham                         Rofl. Its true to its name    None\n\n[5574 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Message</th>\n      <th>Column3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>Will ü b going to esplanade fr home?</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5572</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5573</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>5574 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664274705273
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to compute target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "cluster_name = \"capstone-compute-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # To use a different region for the compute, add a location='<region>' parameter\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress.\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664257891662
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AutoML Configuration\n",
        "\n",
        "- task: \"classification\" because we are performing multi-class classification\n",
        "- label_column_name: \"Category\" because we want to predict that \n",
        "- experiment_timeout_hours: 0.25 because we want the experiment to run for max 15 min"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "automl_settings = {\n",
        "    \"n_cross_validations\": 2,\n",
        "    \"primary_metric\": 'accuracy',\n",
        "    \"enable_early_stopping\": True,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"experiment_timeout_hours\": 0.25,\n",
        "    \"featurization\": 'auto',\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task = 'classification',\n",
        "    compute_target = compute_target,\n",
        "    training_data = training_dataset,\n",
        "    label_column_name = 'Category',\n",
        "    **automl_settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1664257891741
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit the experiment\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>capstone-spam-classification-experiment</td><td>AutoML_264ce6fc-7280-41c7-9d44-b02c767bf5bd</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_264ce6fc-7280-41c7-9d44-b02c767bf5bd?wsid=/subscriptions/aa7cf8e8-d23f-4bce-a7b9-1f0b4e0ac8ee/resourcegroups/aml-quickstarts-209041/workspaces/quick-starts-ws-209041&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1664257894666
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Details"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664257958688
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1664175125474
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the best model and display its properties"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = remote_run.get_output()\n",
        "\n",
        "# Get best_run metrics\n",
        "print(best_run)\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "for name, value in best_run_metrics.items():\n",
        "    print(f\"{name}: {value}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664181877933
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_file_names()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664175142848
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best parameters of AutoML model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model.steps[1][1].get_params()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "{'base_learners': None,\n 'meta_learner': None,\n 'training_cv_folds': None,\n '15': Pipeline(memory=None,\n          steps=[('standardscalerwrapper',\n                  StandardScalerWrapper(copy=True, with_mean=False, with_std=False)),\n                 ('logisticregression',\n                  LogisticRegression(C=51.79474679231202, class_weight=None,\n                                     dual=False, fit_intercept=True,\n                                     intercept_scaling=1, l1_ratio=None,\n                                     max_iter=100, multi_class='ovr', n_jobs=1,\n                                     penalty='l2', random_state=None,\n                                     solver='lbfgs', tol=0.0001, verbose=0,\n                                     warm_start=False))],\n          verbose=False),\n '36': Pipeline(memory=None,\n          steps=[('standardscalerwrapper',\n                  StandardScalerWrapper(copy=True, with_mean=False, with_std=False)),\n                 ('logisticregression',\n                  LogisticRegression(C=16.768329368110066, class_weight=None,\n                                     dual=False, fit_intercept=True,\n                                     intercept_scaling=1, l1_ratio=None,\n                                     max_iter=100, multi_class='ovr', n_jobs=1,\n                                     penalty='l2', random_state=None,\n                                     solver='lbfgs', tol=0.0001, verbose=0,\n                                     warm_start=False))],\n          verbose=False),\n '27': Pipeline(memory=None,\n          steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n                 ('logisticregression',\n                  LogisticRegression(C=339.3221771895323, class_weight=None,\n                                     dual=False, fit_intercept=True,\n                                     intercept_scaling=1, l1_ratio=None,\n                                     max_iter=100, multi_class='ovr', n_jobs=1,\n                                     penalty='l2', random_state=None,\n                                     solver='newton-cg', tol=0.0001, verbose=0,\n                                     warm_start=False))],\n          verbose=False),\n '12': Pipeline(memory=None,\n          steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n                 ('logisticregression',\n                  LogisticRegression(C=719.6856730011514, class_weight=None,\n                                     dual=False, fit_intercept=True,\n                                     intercept_scaling=1, l1_ratio=None,\n                                     max_iter=100, multi_class='multinomial',\n                                     n_jobs=1, penalty='l2', random_state=None,\n                                     solver='lbfgs', tol=0.0001, verbose=0,\n                                     warm_start=False))],\n          verbose=False),\n '32': Pipeline(memory=None,\n          steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n                 ('logisticregression',\n                  LogisticRegression(C=5.428675439323859, class_weight=None,\n                                     dual=False, fit_intercept=True,\n                                     intercept_scaling=1, l1_ratio=None,\n                                     max_iter=100, multi_class='ovr', n_jobs=1,\n                                     penalty='l2', random_state=None,\n                                     solver='newton-cg', tol=0.0001, verbose=0,\n                                     warm_start=False))],\n          verbose=False),\n '33': Pipeline(memory=None,\n          steps=[('sparsenormalizer', Normalizer(copy=True, norm='l2')),\n                 ('xgboostclassifier',\n                  XGBoostClassifier(booster='gbtree', colsample_bytree=0.8, eta=0.3, gamma=0, max_depth=10, max_leaves=0, n_estimators=50, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=1.6666666666666667, subsample=0.7, tree_method='auto'))],\n          verbose=False),\n '3': Pipeline(memory=None,\n          steps=[('sparsenormalizer', Normalizer(copy=True, norm='l2')),\n                 ('xgboostclassifier',\n                  XGBoostClassifier(booster='gbtree', colsample_bytree=0.7, eta=0.01, gamma=0.01, max_depth=7, max_leaves=31, n_estimators=10, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=2.1875, reg_lambda=1.0416666666666667, subsample=1, tree_method='auto'))],\n          verbose=False),\n '2': Pipeline(memory=None,\n          steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n                 ('extratreesclassifier',\n                  ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,\n                                       class_weight='balanced', criterion='gini',\n                                       max_depth=None, max_features='sqrt',\n                                       max_leaf_nodes=None, max_samples=None,\n                                       min_impurity_decrease=0.0,\n                                       min_impurity_split=None,\n                                       min_samples_leaf=0.01,\n                                       min_samples_split=0.15052631578947367,\n                                       min_weight_fraction_leaf=0.0,\n                                       n_estimators=100, n_jobs=1,\n                                       oob_score=True, random_state=None,\n                                       verbose=0, warm_start=False))],\n          verbose=False),\n '15__memory': None,\n '15__steps': [('standardscalerwrapper',\n   StandardScalerWrapper(copy=True, with_mean=False, with_std=False)),\n  ('logisticregression',\n   LogisticRegression(C=51.79474679231202, class_weight=None, dual=False,\n                      fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                      max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                      warm_start=False))],\n '15__verbose': False,\n '15__standardscalerwrapper': StandardScalerWrapper(copy=True, with_mean=False, with_std=False),\n '15__logisticregression': LogisticRegression(C=51.79474679231202, class_weight=None, dual=False,\n                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                    max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                    warm_start=False),\n '15__standardscalerwrapper__module_name': 'sklearn.preprocessing._data',\n '15__standardscalerwrapper__class_name': 'StandardScaler',\n '15__standardscalerwrapper__copy': True,\n '15__standardscalerwrapper__with_mean': False,\n '15__standardscalerwrapper__with_std': False,\n '15__logisticregression__C': 51.79474679231202,\n '15__logisticregression__class_weight': None,\n '15__logisticregression__dual': False,\n '15__logisticregression__fit_intercept': True,\n '15__logisticregression__intercept_scaling': 1,\n '15__logisticregression__l1_ratio': None,\n '15__logisticregression__max_iter': 100,\n '15__logisticregression__multi_class': 'ovr',\n '15__logisticregression__n_jobs': 1,\n '15__logisticregression__penalty': 'l2',\n '15__logisticregression__random_state': None,\n '15__logisticregression__solver': 'lbfgs',\n '15__logisticregression__tol': 0.0001,\n '15__logisticregression__verbose': 0,\n '15__logisticregression__warm_start': False,\n '36__memory': None,\n '36__steps': [('standardscalerwrapper',\n   StandardScalerWrapper(copy=True, with_mean=False, with_std=False)),\n  ('logisticregression',\n   LogisticRegression(C=16.768329368110066, class_weight=None, dual=False,\n                      fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                      max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                      warm_start=False))],\n '36__verbose': False,\n '36__standardscalerwrapper': StandardScalerWrapper(copy=True, with_mean=False, with_std=False),\n '36__logisticregression': LogisticRegression(C=16.768329368110066, class_weight=None, dual=False,\n                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                    max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                    warm_start=False),\n '36__standardscalerwrapper__module_name': 'sklearn.preprocessing._data',\n '36__standardscalerwrapper__class_name': 'StandardScaler',\n '36__standardscalerwrapper__copy': True,\n '36__standardscalerwrapper__with_mean': False,\n '36__standardscalerwrapper__with_std': False,\n '36__logisticregression__C': 16.768329368110066,\n '36__logisticregression__class_weight': None,\n '36__logisticregression__dual': False,\n '36__logisticregression__fit_intercept': True,\n '36__logisticregression__intercept_scaling': 1,\n '36__logisticregression__l1_ratio': None,\n '36__logisticregression__max_iter': 100,\n '36__logisticregression__multi_class': 'ovr',\n '36__logisticregression__n_jobs': 1,\n '36__logisticregression__penalty': 'l2',\n '36__logisticregression__random_state': None,\n '36__logisticregression__solver': 'lbfgs',\n '36__logisticregression__tol': 0.0001,\n '36__logisticregression__verbose': 0,\n '36__logisticregression__warm_start': False,\n '27__memory': None,\n '27__steps': [('maxabsscaler', MaxAbsScaler(copy=True)),\n  ('logisticregression',\n   LogisticRegression(C=339.3221771895323, class_weight=None, dual=False,\n                      fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                      max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                      random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n                      warm_start=False))],\n '27__verbose': False,\n '27__maxabsscaler': MaxAbsScaler(copy=True),\n '27__logisticregression': LogisticRegression(C=339.3221771895323, class_weight=None, dual=False,\n                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                    max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                    random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n                    warm_start=False),\n '27__maxabsscaler__copy': True,\n '27__logisticregression__C': 339.3221771895323,\n '27__logisticregression__class_weight': None,\n '27__logisticregression__dual': False,\n '27__logisticregression__fit_intercept': True,\n '27__logisticregression__intercept_scaling': 1,\n '27__logisticregression__l1_ratio': None,\n '27__logisticregression__max_iter': 100,\n '27__logisticregression__multi_class': 'ovr',\n '27__logisticregression__n_jobs': 1,\n '27__logisticregression__penalty': 'l2',\n '27__logisticregression__random_state': None,\n '27__logisticregression__solver': 'newton-cg',\n '27__logisticregression__tol': 0.0001,\n '27__logisticregression__verbose': 0,\n '27__logisticregression__warm_start': False,\n '12__memory': None,\n '12__steps': [('maxabsscaler', MaxAbsScaler(copy=True)),\n  ('logisticregression',\n   LogisticRegression(C=719.6856730011514, class_weight=None, dual=False,\n                      fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                      max_iter=100, multi_class='multinomial', n_jobs=1,\n                      penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n                      verbose=0, warm_start=False))],\n '12__verbose': False,\n '12__maxabsscaler': MaxAbsScaler(copy=True),\n '12__logisticregression': LogisticRegression(C=719.6856730011514, class_weight=None, dual=False,\n                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                    max_iter=100, multi_class='multinomial', n_jobs=1,\n                    penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n                    verbose=0, warm_start=False),\n '12__maxabsscaler__copy': True,\n '12__logisticregression__C': 719.6856730011514,\n '12__logisticregression__class_weight': None,\n '12__logisticregression__dual': False,\n '12__logisticregression__fit_intercept': True,\n '12__logisticregression__intercept_scaling': 1,\n '12__logisticregression__l1_ratio': None,\n '12__logisticregression__max_iter': 100,\n '12__logisticregression__multi_class': 'multinomial',\n '12__logisticregression__n_jobs': 1,\n '12__logisticregression__penalty': 'l2',\n '12__logisticregression__random_state': None,\n '12__logisticregression__solver': 'lbfgs',\n '12__logisticregression__tol': 0.0001,\n '12__logisticregression__verbose': 0,\n '12__logisticregression__warm_start': False,\n '32__memory': None,\n '32__steps': [('maxabsscaler', MaxAbsScaler(copy=True)),\n  ('logisticregression',\n   LogisticRegression(C=5.428675439323859, class_weight=None, dual=False,\n                      fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                      max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                      random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n                      warm_start=False))],\n '32__verbose': False,\n '32__maxabsscaler': MaxAbsScaler(copy=True),\n '32__logisticregression': LogisticRegression(C=5.428675439323859, class_weight=None, dual=False,\n                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                    max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n                    random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n                    warm_start=False),\n '32__maxabsscaler__copy': True,\n '32__logisticregression__C': 5.428675439323859,\n '32__logisticregression__class_weight': None,\n '32__logisticregression__dual': False,\n '32__logisticregression__fit_intercept': True,\n '32__logisticregression__intercept_scaling': 1,\n '32__logisticregression__l1_ratio': None,\n '32__logisticregression__max_iter': 100,\n '32__logisticregression__multi_class': 'ovr',\n '32__logisticregression__n_jobs': 1,\n '32__logisticregression__penalty': 'l2',\n '32__logisticregression__random_state': None,\n '32__logisticregression__solver': 'newton-cg',\n '32__logisticregression__tol': 0.0001,\n '32__logisticregression__verbose': 0,\n '32__logisticregression__warm_start': False,\n '33__memory': None,\n '33__steps': [('sparsenormalizer', Normalizer(copy=True, norm='l2')),\n  ('xgboostclassifier',\n   XGBoostClassifier(booster='gbtree', colsample_bytree=0.8, eta=0.3, gamma=0, max_depth=10, max_leaves=0, n_estimators=50, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=1.6666666666666667, subsample=0.7, tree_method='auto'))],\n '33__verbose': False,\n '33__sparsenormalizer': Normalizer(copy=True, norm='l2'),\n '33__xgboostclassifier': XGBoostClassifier(booster='gbtree', colsample_bytree=0.8, eta=0.3, gamma=0, max_depth=10, max_leaves=0, n_estimators=50, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=1.6666666666666667, subsample=0.7, tree_method='auto'),\n '33__sparsenormalizer__norm': 'l2',\n '33__sparsenormalizer__copy': True,\n '33__xgboostclassifier__objective': 'multi:softprob',\n '33__xgboostclassifier__use_label_encoder': True,\n '33__xgboostclassifier__base_score': 0.5,\n '33__xgboostclassifier__booster': 'gbtree',\n '33__xgboostclassifier__colsample_bylevel': 1,\n '33__xgboostclassifier__colsample_bynode': 1,\n '33__xgboostclassifier__colsample_bytree': 0.8,\n '33__xgboostclassifier__gamma': 0,\n '33__xgboostclassifier__gpu_id': -1,\n '33__xgboostclassifier__importance_type': 'gain',\n '33__xgboostclassifier__interaction_constraints': '',\n '33__xgboostclassifier__learning_rate': 0.300000012,\n '33__xgboostclassifier__max_delta_step': 0,\n '33__xgboostclassifier__max_depth': 10,\n '33__xgboostclassifier__min_child_weight': 1,\n '33__xgboostclassifier__missing': nan,\n '33__xgboostclassifier__monotone_constraints': '()',\n '33__xgboostclassifier__n_estimators': 50,\n '33__xgboostclassifier__n_jobs': 1,\n '33__xgboostclassifier__num_parallel_tree': 1,\n '33__xgboostclassifier__random_state': 0,\n '33__xgboostclassifier__reg_alpha': 0,\n '33__xgboostclassifier__reg_lambda': 1.6666666666666667,\n '33__xgboostclassifier__scale_pos_weight': None,\n '33__xgboostclassifier__subsample': 0.7,\n '33__xgboostclassifier__tree_method': 'auto',\n '33__xgboostclassifier__validate_parameters': 1,\n '33__xgboostclassifier__verbosity': 0,\n '33__xgboostclassifier__eta': 0.3,\n '33__xgboostclassifier__max_leaves': 0,\n '33__xgboostclassifier__verbose': -10,\n '3__memory': None,\n '3__steps': [('sparsenormalizer', Normalizer(copy=True, norm='l2')),\n  ('xgboostclassifier',\n   XGBoostClassifier(booster='gbtree', colsample_bytree=0.7, eta=0.01, gamma=0.01, max_depth=7, max_leaves=31, n_estimators=10, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=2.1875, reg_lambda=1.0416666666666667, subsample=1, tree_method='auto'))],\n '3__verbose': False,\n '3__sparsenormalizer': Normalizer(copy=True, norm='l2'),\n '3__xgboostclassifier': XGBoostClassifier(booster='gbtree', colsample_bytree=0.7, eta=0.01, gamma=0.01, max_depth=7, max_leaves=31, n_estimators=10, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=2.1875, reg_lambda=1.0416666666666667, subsample=1, tree_method='auto'),\n '3__sparsenormalizer__norm': 'l2',\n '3__sparsenormalizer__copy': True,\n '3__xgboostclassifier__objective': 'multi:softprob',\n '3__xgboostclassifier__use_label_encoder': True,\n '3__xgboostclassifier__base_score': 0.5,\n '3__xgboostclassifier__booster': 'gbtree',\n '3__xgboostclassifier__colsample_bylevel': 1,\n '3__xgboostclassifier__colsample_bynode': 1,\n '3__xgboostclassifier__colsample_bytree': 0.7,\n '3__xgboostclassifier__gamma': 0.01,\n '3__xgboostclassifier__gpu_id': -1,\n '3__xgboostclassifier__importance_type': 'gain',\n '3__xgboostclassifier__interaction_constraints': '',\n '3__xgboostclassifier__learning_rate': 0.00999999978,\n '3__xgboostclassifier__max_delta_step': 0,\n '3__xgboostclassifier__max_depth': 7,\n '3__xgboostclassifier__min_child_weight': 1,\n '3__xgboostclassifier__missing': nan,\n '3__xgboostclassifier__monotone_constraints': '()',\n '3__xgboostclassifier__n_estimators': 10,\n '3__xgboostclassifier__n_jobs': 1,\n '3__xgboostclassifier__num_parallel_tree': 1,\n '3__xgboostclassifier__random_state': 0,\n '3__xgboostclassifier__reg_alpha': 2.1875,\n '3__xgboostclassifier__reg_lambda': 1.0416666666666667,\n '3__xgboostclassifier__scale_pos_weight': None,\n '3__xgboostclassifier__subsample': 1,\n '3__xgboostclassifier__tree_method': 'auto',\n '3__xgboostclassifier__validate_parameters': 1,\n '3__xgboostclassifier__verbosity': 0,\n '3__xgboostclassifier__eta': 0.01,\n '3__xgboostclassifier__max_leaves': 31,\n '3__xgboostclassifier__verbose': -10,\n '2__memory': None,\n '2__steps': [('maxabsscaler', MaxAbsScaler(copy=True)),\n  ('extratreesclassifier',\n   ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n                        criterion='gini', max_depth=None, max_features='sqrt',\n                        max_leaf_nodes=None, max_samples=None,\n                        min_impurity_decrease=0.0, min_impurity_split=None,\n                        min_samples_leaf=0.01,\n                        min_samples_split=0.15052631578947367,\n                        min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n                        oob_score=True, random_state=None, verbose=0,\n                        warm_start=False))],\n '2__verbose': False,\n '2__maxabsscaler': MaxAbsScaler(copy=True),\n '2__extratreesclassifier': ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n                      criterion='gini', max_depth=None, max_features='sqrt',\n                      max_leaf_nodes=None, max_samples=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=0.01,\n                      min_samples_split=0.15052631578947367,\n                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n                      oob_score=True, random_state=None, verbose=0,\n                      warm_start=False),\n '2__maxabsscaler__copy': True,\n '2__extratreesclassifier__bootstrap': True,\n '2__extratreesclassifier__ccp_alpha': 0.0,\n '2__extratreesclassifier__class_weight': 'balanced',\n '2__extratreesclassifier__criterion': 'gini',\n '2__extratreesclassifier__max_depth': None,\n '2__extratreesclassifier__max_features': 'sqrt',\n '2__extratreesclassifier__max_leaf_nodes': None,\n '2__extratreesclassifier__max_samples': None,\n '2__extratreesclassifier__min_impurity_decrease': 0.0,\n '2__extratreesclassifier__min_impurity_split': None,\n '2__extratreesclassifier__min_samples_leaf': 0.01,\n '2__extratreesclassifier__min_samples_split': 0.15052631578947367,\n '2__extratreesclassifier__min_weight_fraction_leaf': 0.0,\n '2__extratreesclassifier__n_estimators': 100,\n '2__extratreesclassifier__n_jobs': 1,\n '2__extratreesclassifier__oob_score': True,\n '2__extratreesclassifier__random_state': None,\n '2__extratreesclassifier__verbose': 0,\n '2__extratreesclassifier__warm_start': False,\n 'metalearner__C': 1.0,\n 'metalearner__class_weight': None,\n 'metalearner__dual': False,\n 'metalearner__fit_intercept': True,\n 'metalearner__intercept_scaling': 1,\n 'metalearner__l1_ratio': None,\n 'metalearner__max_iter': 100,\n 'metalearner__multi_class': 'auto',\n 'metalearner__n_jobs': None,\n 'metalearner__penalty': 'l2',\n 'metalearner__random_state': None,\n 'metalearner__solver': 'lbfgs',\n 'metalearner__tol': 0.0001,\n 'metalearner__verbose': 0,\n 'metalearner__warm_start': False}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664283419211
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(fitted_model, 'best-automl-model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664175146913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the best model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "model = Model.register(\n",
        "    workspace=ws, \n",
        "    model_name='best-automl-model', \n",
        "    model_path='./best-automl-model.pkl'\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664175147997
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an inference config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Get the environment\n",
        "from azureml.automl.core.shared import constants\n",
        "\n",
        "best_run.download_file(constants.CONDA_ENV_FILE_PATH, 'conda_dependencies.yml')\n",
        "env = Environment.from_conda_specification(name='deployment-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "inference_config = InferenceConfig(\n",
        "    environment=env,\n",
        "    source_directory=\".\",\n",
        "    entry_script=\"./automl_score.py\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664182077904
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the deployment config - we deploy on Azure Container Instance (ACI)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1, memory_gb=2, auth_enabled=True, enable_app_insights=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664182078955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy the model as a web service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "service = Model.deploy(\n",
        "    ws,\n",
        "    \"automl-service\",\n",
        "    [model],\n",
        "    inference_config,\n",
        "    deployment_config,\n",
        "    overwrite=True,\n",
        ")\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664182368363
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send a request to the web service you deployed to test it"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from azureml.core import Webservice\n",
        "\n",
        "service = Webservice(workspace=ws, name=\"automl-service\")\n",
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "# If the service is authenticated, set the key or token\n",
        "key, _ = service.get_keys()\n",
        "\n",
        "# Set the appropriate headers\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "\n",
        "# Make the request and display the response and logs\n",
        "data =  {\n",
        "  \"Inputs\": {\n",
        "    \"data\": [\n",
        "      {\n",
        "        \"Message\": \"Welcome to Airways!\",\n",
        "        \"Column3\": \"\"\n",
        "     }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "input_data = json.dumps(data)\n",
        "resp = requests.post(scoring_uri, data=input_data, headers=headers)\n",
        "print(resp.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\"result\": [\"ham\"]}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4de332cd90>: Failed to establish a new connection: [Errno 111] Connection refused')': /history/v1.0/subscriptions/aa7cf8e8-d23f-4bce-a7b9-1f0b4e0ac8ee/resourceGroups/aml-quickstarts-209041/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-209041/experiments/capstone-spam-classification-experiment/runs/AutoML_264ce6fc-7280-41c7-9d44-b02c767bf5bd/details\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1664274724449
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the logs of the web service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-09-26T07:26:28,453535500+00:00 - iot-server/run \n2022-09-26T07:26:28,460346000+00:00 - rsyslog/run \nbash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by bash)\n2022-09-26T07:26:28,488064600+00:00 - gunicorn/run \n2022-09-26T07:26:28,491386500+00:00 - nginx/run \n2022-09-26T07:26:28,506808600+00:00 | gunicorn/run | \n2022-09-26T07:26:28,521812500+00:00 | gunicorn/run | ###############################################\nrsyslogd: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libuuid.so.1: no version information available (required by rsyslogd)\n2022-09-26T07:26:28,551252400+00:00 | gunicorn/run | AzureML Container Runtime Information\n2022-09-26T07:26:28,555507400+00:00 | gunicorn/run | ###############################################\n2022-09-26T07:26:28,563877800+00:00 | gunicorn/run | \n2022-09-26T07:26:28,595100700+00:00 | gunicorn/run | \n2022-09-26T07:26:28,623813700+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220708.v2\n2022-09-26T07:26:28,626858400+00:00 | gunicorn/run | \n2022-09-26T07:26:28,632387600+00:00 | gunicorn/run | \n2022-09-26T07:26:28,637930300+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2022-09-26T07:26:28,641489900+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2022-09-26T07:26:28,642790200+00:00 | gunicorn/run | \n2022-09-26T07:26:28,644078300+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n/bin/bash: /azureml-envs/azureml_944df6c9e2b12a3bdcde13b5b8baccf0/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-09-26T07:26:28,849343700+00:00 - iot-server/finish 1 0\n2022-09-26T07:26:28,850949500+00:00 - Exit code 1 is normal. Not restarting iot-server.\nadal==1.2.7\napplicationinsights==0.11.10\nargcomplete==2.0.0\nattrs==22.1.0\nazure-common==1.1.28\nazure-core==1.25.1\nazure-graphrbac==0.61.1\nazure-identity==1.7.0\nazure-mgmt-authorization==2.0.0\nazure-mgmt-containerregistry==10.0.0\nazure-mgmt-core==1.3.2\nazure-mgmt-keyvault==10.1.0\nazure-mgmt-resource==21.1.0\nazure-mgmt-storage==20.0.0\nazure-storage-blob==12.13.0\nazure-storage-queue==12.4.0\nazureml-automl-core==1.45.0\nazureml-automl-runtime==1.45.0\nazureml-core==1.45.0.post2\nazureml-dataprep==4.2.2\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.8.1\nazureml-dataset-runtime==1.45.0\nazureml-defaults==1.45.0\nazureml-inference-server-http==0.7.6\nazureml-interpret==1.45.0\nazureml-mlflow==1.45.0\nazureml-telemetry==1.45.0\nazureml-train-automl-client==1.45.0\nazureml-train-automl-runtime==1.45.0\nazureml-train-core==1.45.0\nazureml-train-restclients-hyperdrive==1.45.0\nazureml-training-tabular==1.45.0\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.0\nbokeh==2.4.3\nboto==2.49.0\nboto3==1.20.19\nbotocore==1.23.19\ncachetools==5.2.0\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\ncffi==1.15.1\ncharset-normalizer==2.1.1\nclick==7.1.2\ncloudpickle==2.2.0\nconfigparser==3.7.4\ncontextlib2==21.6.0\nconvertdate @ file:///tmp/build/80754af9/convertdate_1634070773133/work\ncryptography==37.0.4\ncycler @ file:///tmp/build/80754af9/cycler_1637851556182/work\nCython==0.29.17\ndask==2.30.0\ndatabricks-cli==0.17.3\ndataclasses==0.6\ndill==0.3.5.1\ndistributed==2.30.1\ndistro==1.7.0\ndocker==5.0.3\ndotnetcore2==3.1.23\nentrypoints==0.4\nephem @ file:///tmp/build/80754af9/ephem_1638960312619/work\nfbprophet @ file:///home/conda/feedstock_root/build_artifacts/fbprophet_1599365534439/work\nfire==0.4.0\nFlask==1.1.4\nFlask-Cors==3.0.10\nflatbuffers==2.0.7\nfonttools==4.25.0\nfsspec==2022.8.2\nfusepy==3.0.1\ngensim==3.8.3\ngitdb==4.0.9\nGitPython==3.1.27\ngoogle-api-core==2.10.1\ngoogle-auth==2.11.1\ngoogleapis-common-protos==1.56.4\ngunicorn==20.1.0\nHeapDict==1.0.1\nholidays @ file:///home/conda/feedstock_root/build_artifacts/holidays_1595448845196/work\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==4.12.0\nimportlib-resources==5.9.0\ninference-schema==1.4.2.1\ninterpret-community==0.26.0\ninterpret-core==0.2.7\nisodate==0.6.1\nitsdangerous==1.1.0\njeepney==0.8.0\nJinja2==2.11.2\njmespath==0.10.0\njoblib==0.14.1\njson-logging-py==0.2\njsonpickle==2.2.0\njsonschema==4.16.0\nkeras2onnx==1.6.0\nkiwisolver @ file:///opt/conda/conda-bld/kiwisolver_1653292039266/work\nknack==0.9.0\nkorean-lunar-calendar @ file:///tmp/build/80754af9/korean_lunar_calendar_1634063020401/work\nlightgbm==3.2.1\nllvmlite==0.38.1\nlocket==1.0.0\nLunarCalendar @ file:///tmp/build/80754af9/lunarcalendar_1646383991234/work\nMarkupSafe==2.0.1\nmatplotlib @ file:///tmp/build/80754af9/matplotlib-suite_1647441664166/work\nml-wrappers==0.2.0\nmlflow-skinny==1.29.0\nmsal==1.19.0\nmsal-extensions==0.3.1\nmsgpack==1.0.4\nmsrest==0.7.1\nmsrestazure==0.6.4\nmunkres==1.1.4\nndg-httpsclient==0.5.1\nnimbusml==1.8.0\nnumba==0.55.2\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1649806299270/work\noauthlib==3.2.1\nonnx==1.12.0\nonnxconverter-common==1.6.0\nonnxmltools==1.4.1\nonnxruntime==1.11.1\nopencensus==0.11.0\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.7\npackaging @ file:///tmp/build/80754af9/packaging_1637314298585/work\npandas==1.1.5\nparamiko==2.11.0\npartd==1.3.0\npathspec==0.10.1\npatsy==0.5.2\nPillow==9.2.0\npkginfo==1.8.3\npkgutil_resolve_name==1.3.10\nply==3.11\npmdarima==1.7.1\nportalocker==2.5.1\nprotobuf==3.20.1\npsutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work\npyarrow==6.0.0\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\nPygments==2.13.0\nPyJWT==2.5.0\nPyMeeus @ file:///tmp/build/80754af9/pymeeus_1634069098549/work\nPyNaCl==1.5.0\npyOpenSSL==22.0.0\npyparsing @ file:///tmp/build/80754af9/pyparsing_1635766073266/work\nPyQt5-sip==12.11.0\npyrsistent==0.18.1\nPySocks==1.7.1\npystan==2.17.1.0\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\npytz @ file:///opt/conda/conda-bld/pytz_1654762638606/work\nPyYAML==6.0\nrequests==2.28.1\nrequests-oauthlib==1.3.1\nrsa==4.9\ns3transfer==0.5.2\nscikit-learn==0.22.1\nscipy==1.5.3\nSecretStorage==3.3.3\nshap==0.39.0\nsip @ file:///tmp/abs_44cd77b_pu/croots/recipe/sip_1659012365470/work\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nskl2onnx==1.4.9\nsklearn-pandas==1.7.0\nslicer==0.0.7\nsmart-open==1.9.0\nsmmap==5.0.0\nsortedcontainers==2.4.0\nsqlparse==0.4.3\nstatsmodels==0.11.1\ntabulate==0.8.10\ntblib==1.7.0\ntermcolor==2.0.1\ntoml @ file:///tmp/build/80754af9/toml_1616166611790/work\ntoolz==0.12.0\ntornado @ file:///tmp/build/80754af9/tornado_1606942283357/work\ntqdm @ file:///opt/conda/conda-bld/tqdm_1650891076910/work\ntypes-cryptography==3.3.23\ntyping_extensions @ file:///tmp/abs_ben9emwtky/croots/recipe/typing_extensions_1659638822008/work\nurllib3==1.26.12\nwebsocket-client==1.4.1\nWerkzeug==1.0.1\nwrapt==1.12.1\nxgboost==1.3.3\nzict==2.2.0\nzipp==3.8.1\n\n2022-09-26T07:26:31,022903100+00:00 | gunicorn/run | \n2022-09-26T07:26:31,025242700+00:00 | gunicorn/run | ###############################################\n2022-09-26T07:26:31,027567300+00:00 | gunicorn/run | AzureML Inference Server\n2022-09-26T07:26:31,033944700+00:00 | gunicorn/run | ###############################################\n2022-09-26T07:26:31,036568300+00:00 | gunicorn/run | \n2022-09-26T07:26:35,053938300+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\nValid Application Insights instrumentation key provided.\n\nAzure ML Inferencing HTTP server v0.7.6\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/odl_user_208897/automl_score.py\nModel Directory: /var/azureml-app/azureml-models/best-automl-model/1\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: true\nApplication Insights Key: AppInsights key provided\nInferencing HTTP server version: azmlinfsrv/0.7.6\nCORS for the specified origins: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\nStarting gunicorn 20.1.0\nListening at: http://0.0.0.0:31311 (79)\nUsing worker: sync\nBooting worker with pid: 135\nInitializing logger\n2022-09-26 07:26:36,344 | root | INFO | Starting up app insights client\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-09-26 07:26:41,587 | root | INFO | Starting up app insight hooks\n2022-09-26 07:26:42,359 | root | INFO | Found user script at /var/azureml-app/odl_user_208897/automl_score.py\n2022-09-26 07:26:42,359 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n2022-09-26 07:26:42,359 | root | INFO | Invoking user's init function\n2022-09-26 07:26:54,748 | root | INFO | Users's init has completed successfully\n2022-09-26 07:26:54,753 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n2022-09-26 07:26:54,754 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n2022-09-26 07:26:54,754 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set, but patching is not necessary.\n2022-09-26 07:27:06,345 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:27:06 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:27:10,616 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:27:10 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:27:11,062 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:27:11 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:27:11,693 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:27:11 +0000] \"POST /score HTTP/1.0\" 200 25 \"-\" \"python-requests/2.28.1\"\n2022-09-26 07:30:16,252 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:30:16 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:30:31,927 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:30:31 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:30:32,565 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:30:32 +0000] \"POST /score HTTP/1.0\" 200 25 \"-\" \"python-requests/2.28.1\"\n2022-09-26 07:30:42,110 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:30:42 +0000] \"GET /swagger.json HTTP/1.0\" 200 2261 \"-\" \"Go-http-client/1.1\"\n2022-09-26 07:30:42,505 | root | INFO | 200\n127.0.0.1 - - [26/Sep/2022:07:30:42 +0000] \"POST /score HTTP/1.0\" 200 25 \"-\" \"python-requests/2.28.1\"\n\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1664177449099
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete the web service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1664177641930
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shutdown the computes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    instance = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "\n",
        "    instance.delete()\n",
        "    instance.wait_for_completion(show_output=True)\n",
        "    print('Deleted compute resource')\n",
        "\n",
        "except ComputeTargetException as e:\n",
        "    print('Already deleted!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress.....Current provisioning state of AmlCompute is \"Deleting\"\n\n..\nSucceededProvisioning operation finished, operation \"Succeeded\"\nComputeTargetException:\n\tMessage: ComputeTargetNotFound: Compute Target with name capstone-compute-cluster not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"ComputeTargetNotFound: Compute Target with name capstone-compute-cluster not found in provided workspace\"\n    }\n}\nAlready deleted!\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1664181179221
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}